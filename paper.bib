@InProceedings{10.1007/978-3-662-46641-4_40,
author="Gupta, Shubham
and Szekely, Pedro
and Knoblock, Craig A.
and Goel, Aman
and Taheriyan, Mohsen
and Muslea, Maria",
editor="Simperl, Elena
and Norton, Barry
and Mladenic, Dunja
and Della Valle, Emanuele
and Fundulaki, Irini
and Passant, Alexandre
and Troncy, Rapha{\"e}l",
title="Karma: A System for Mapping Structured Sources into the Semantic Web",
booktitle="The Semantic Web: ESWC 2012 Satellite Events",
year="2015",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="430--434",
abstract="The Linked Data cloud contains large amounts of RDF data generated from databases.",
isbn="978-3-662-46641-4",
doi = {10.1007/978-3-662-46641-4_40}
}

@article{HARRIS2019103208,
title = {The REDCap consortium: Building an international community of software platform partners},
journal = {Journal of Biomedical Informatics},
volume = {95},
pages = {103208},
year = {2019},
issn = {1532-0464},
doi = {10.1016/j.jbi.2019.103208},
url = {https://www.sciencedirect.com/science/article/pii/S1532046419301261},
author = {Paul A. Harris and Robert Taylor and Brenda L. Minor and Veida Elliott and Michelle Fernandez and Lindsay O'Neal and Laura McLeod and Giovanni Delacqua and Francesco Delacqua and Jacqueline Kirby and Stephany N. Duda},
keywords = {Medical informatics, Electronic data capture, Clinical research, Translational research},
abstract = {The Research Electronic Data Capture (REDCap) data management platform was developed in 2004 to address an institutional need at Vanderbilt University, then shared with a limited number of adopting sites beginning in 2006. Given bi-directional benefit in early sharing experiments, we created a broader consortium sharing and support model for any academic, non-profit, or government partner wishing to adopt the software. Our sharing framework and consortium-based support model have evolved over time along with the size of the consortium (currently more than 3200 REDCap partners across 128 countries). While the “REDCap Consortium” model represents only one example of how to build and disseminate a software platform, lessons learned from our approach may assist other research institutions seeking to build and disseminate innovative technologies.}
}

@article{HARRIS2009377,
title = {Research electronic data capture (REDCap)—A metadata-driven methodology and workflow process for providing translational research informatics support},
journal = {Journal of Biomedical Informatics},
volume = {42},
number = {2},
pages = {377-381},
year = {2009},
issn = {1532-0464},
doi = {10.1016/j.jbi.2008.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S1532046408001226},
author = {Paul A. Harris and Robert Taylor and Robert Thielke and Jonathon Payne and Nathaniel Gonzalez and Jose G. Conde},
keywords = {Medical informatics, Electronic data capture, Clinical research, Translational research},
abstract = {Research electronic data capture (REDCap) is a novel workflow methodology and software solution designed for rapid development and deployment of electronic data capture tools to support clinical and translational research. We present: (1) a brief description of the REDCap metadata-driven software toolset; (2) detail concerning the capture and use of study-related metadata from scientific research teams; (3) measures of impact for REDCap; (4) details concerning a consortium network of domestic and international institutions collaborating on the project; and (5) strengths and limitations of the REDCap system. REDCap is currently supporting 286 translational research projects in a growing collaborative network including 27 active partner institutions.}
}

@article{forbes1,
  author = {Gil Press},
  title = {Cleaning Big Data: Most Time-Consuming, Least Enjoyable Data Science Task, Survey Says},
  journal = {Forbes: ENTERPRISE & CLOUD},
  year = {2016},
  url = {https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/}
}

@article{carnivalcohort,
    author = {David Birtwell, Heather Williams, Reed Pyeritz, Scott Damrauer, Danielle L. Mowery},
    title = "{Carnival: A Graph-Based Data Integration and Query Tool to Support Patient Cohort Generation for Clinical Research}",
    journal = {IOS Press Ebooks},
    year = 2019,
    volume = 264,
    pages = {35-39},
    doi = {10.3233/SHTI190178},
    url = {https://ebooks.iospress.nl/volumearticle/51943},
}

@article{FREEDMAN2020100086,
  title = {A novel tool for standardizing clinical data in a semantically rich model},
  journal = {Journal of Biomedical Informatics},
  volume = {112},
  pages = {100086},
  year = {2020},
  note = {Articles initially published in Journal of Biomedical Informatics: X 5-8, 2020},
  issn = {1532-0464},
  doi = {10.1016/j.yjbinx.2020.100086},
  url = {https://www.sciencedirect.com/science/article/pii/S2590177X20300214},
  author = {Hayden G. Freedman and Heather Williams and Mark A. Miller and David Birtwell and Danielle L. Mowery and Christian J. Stoeckert},
  keywords = {Clinical data, Biomedical ontologies, Common data model, Data interoperability, Semantic Web technologies},
  abstract = {Standardizing clinical information in a semantically rich data model is useful for promoting interoperability and facilitating high quality research. Semantic Web technologies such as Resource Description Framework can be utilized to their full potential when a model accurately reflects the semantics of the clinical situation it describes. To this end, ontologies that abide by sound organizational principles can be used as the building blocks of a semantically rich model for the storage of clinical data. However, it is a challenge to programmatically define such a model and load data from disparate sources. The PennTURBO Semantic Engine is a tool developed at the University of Pennsylvania that transforms concise RDF data into a source-independent, semantically rich model. This system sources classes from an application ontology and specifically defines how instances of those classes may relate to each other. Additionally, the system defines and executes RDF data transformations by launching dynamically generated SPARQL update statements. The Semantic Engine was designed as a generalizable data standardization tool, and is able to work with various data models and incoming data sources. Its human-readable configuration files can easily be shared between institutions, providing the basis for collaboration on a standard data model.}
}
